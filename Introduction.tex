Logs are leveraged by developers to record useful information during the execution of a system. Loinggs are recorded during various developmental activities such as bug fixing~\cite{ConsoleLogs,JGLouMining,QFuanomaly}, performing improvement tasks~\cite{Automatic}, monitoring performance~\cite{Yuan} and for knowledge transfer~\cite{IanWCRE}.
Logging can be done through use of log libraries or archaic methods such as \textsl{print} statements. Every log contains a textual part, which provides information about context, a variable part providing information about the event and a log level, which shows the verbosity of the logs. An example of a log is shown below where info is the logging level, \textsl{Testing Connection to Host Id} to is the event and the value of variable \textsl{host} is the variable part.
\hypobox{LOG.info( ``Testing Connection to Host Id:" + host);}

The rich  and unified format of logs has lead to the development of many log processing tools such as \textsl{Splunk}, \textsl{Xpolog}, \textsl{Logstash} and in-house tools. These log processing tools are used to generate information for capacity planning of large-scale systems~\cite{hassan2008industrial,nagappan2009efficiently}, to monitor system health~\cite{bitincka2010optimizing} or to detect abnormal system behavior~\cite{JiangICSM2008}. These applications rely heavily on the log messages themselves and require continuous maintenance when the format or content of logs are changed. 

%These tools are used for a variety of purposes and not only by developers for developmental activities. They are used to monitor system health, to detect anomalies, to find performance issues and also capacity planning. Because of this new area of log utilization there have been many commercial log processing tools like \textsl{Splunk}, \textsl{Xpolog}, \textsl{Logstash} and in-house tools. These applications reply heavily on the log messages themselves and require continuous maintenance when the format or content of logs are changed. 

Research shows that only 40\% of the logs at execution level, stays the same across releases and the impact of 15-80\% of the changes can be minimized through robust analysis~\cite{IanWCRE}. These log changes, can affect the log processing tools which heavily depend on them and maintenance cost will be high. In this paper, we track the changes made to logs across multiple releases in the four studied systems. In order to get a better understanding of the log changes we focus our research on the following RQ's.

% and use the data to answer the following research questions.

\textbf{RQ1:} \textbf{How much do logs change over time and why do the changes occur?}

Based on our quantitative analysis of the studied systems we identify three categories of change frequency in logs. If a log is changed more than four times we categorize it as \textsl{`Frequently Changed'}, if it has only three changes or less  it is categorized as \textsl{`Changed'} and if there are no changes made we categorize it as \textsl{`Never Changed'}. We find that 20-80\% of all logs are changed at least once throughout the lifespan of our studied systems. We find developers change logs for four main reasons namely:`change of log level', `text modification', `variable modification' and `log relocation'.
% We find that only \textsl{Hadoop} has 60\% of log statements in the \textsl{`Never Changed'} category.In all other projects we find that \textsl{`Changed'} is majority ranging between 20\% - 68\% in CloudStack. We find that \textsl{`Frequently changed'} ranges between 1\% - 13\% in the four subject systems and is the least among the three categories. These results show that logs are not stable and there is need to study the stability of log statements in large subject systems.


\textbf{RQ2:} \textbf{Can code, log and developer metrics help in explaining the stability of logs?}

 We find that code, log and developer related metrics help in building models which can predict which logs are more likely to change in the future. We use the data from three dimensions namely, code, log and developers. Our \textsl{random forest} achieved an accuracy of 89\% to 93\% in all studied systems with recall of 76\% to 92\%, when predicting which logs have higher likelihood of getting changed. We also identify significant metrics from each dimension, that affect the stability of logs. We find several metrics (e.g., developer experience, source lines of code, \# of comments, log text length) are strong predictors in predicting if a log will change in the future. 
 
 
 These results show that code, log and developer related metrics can help in identifying unstable logs in our studied systems. This can help in reducing the effort needed in the maintenance of log processing applications, as system maintainers can flag the logs that have the potential of being changed in subsequent releases and track them. 
 
The rest of this paper is organized as follows. Section~\ref{Methodology} presents the methodology for gathering and extracting data for our study. Section~\ref{studyresults} presents the case studies and the results to answer the two research questions. Section~\ref{related} describes the prior research that is related to our work. Section~\ref{threats} discusses the threats to validity. Finally, Section~\ref{conc} concludes the paper.
 
 
% However, as these tools are not scalable for all companies and systems, companies prefer in house development or customization of these tools for their specific purposes. 