

Logs are leveraged by developers to record useful information during the execution of an application. Logs are recorded during various development activities such as bug fixing~\cite{ConsoleLogs,JGLouMining,QFuanomaly}, load test analysis~\cite{Automatic}, monitoring performance~\cite{Yuan} and for knowledge transfer~\cite{IanWCRE}.
Logging can be done through the use of log libraries or more archaic methods such as \textsl{print} statements. Every log contains a textual part, which provides information about the context, a variable part providing information about the event and a log level, which shows the verbosity of the logs. An example of a log is shown below where info is the logging level, \textsl{Testing Connection to Host Id} is the context information and \textsl{host}, which is the variable part, provides information about the logging context.
\hypobox{LOG.info(``Testing Connection to Host Id:" + host);}

\begin{figure}[tb]
	\centering
	\includegraphics[width=1\columnwidth]{ExampleOfLogChange_LPA}
	\caption{Modification of a logging statement}
	\label{fig:ExampleOfLogChange_LPA}
\end{figure}


The unified format of logs has lead to the development of many enterprise log processing tools such as \textsl{Splunk}~\cite{carasso2012exploring}, \textsl{Xpolog}~\cite{xpolog}, \textsl{Logstash}~\cite{xu2013detecting} and research tools such as Salsa~\cite{TanSalsa}, log-enhancer~\cite{Yuan} and chukwa~\cite{chukwa} which are designed to diagnose as well as improve logging in software applications. However, when logs are changed the log processing tools also have to be updated to reflect the changes to the log. For example, Figure~\ref{fig:ExampleOfLogChange_LPA} demonstrates a case in which a developer removes the time taken for completing an event. This can affect log processing tools that rely on that information for other activities and the data lost is not recoverable. Prior research also shows that 60\% of the logs are changed at execution level across releases~\cite{IanWCRE}. These log changes can affect the log processing tools which heavily depend on them and maintenance cost will be high~\cite{IanWCRE}. 

In this paper, we track the changes made to logs across multiple releases in four studied open source applications. From the preliminary analysis, we find that 45\%-55\% of the logs are changed at least once throughout their lifespan in the studied applications. We find that a single log changes between 1 to 12 times within their lifetime and can be changed by more than one developer. To identify which factors play vital role in the stability of logging statements, we build a random forest classifier using change and process metrics. From the random forest classifier we make the following observations.
\begin{enumerate}
	\item  Our \textsl{random forest} achieves an accuracy of 89\%-91\% and recall of 71\%-91\%, when predicting which logs have higher likelihood of getting changed.
	\item We find that logs introduced by developers who have less ownership of the file are more likely to be changed later than logs written by owners of the file. 
	\item We find that file with higher log density are less likely to have changes to their logs than files with lesser log density.
	\item We find that developer experience is negatively correlated in the studied applications, suggesting that log introduced by more experienced developers are more stable. 
	\item We find that change metrics like SLOC, number of variables logged, number of variables declared are strong predictors of log stability within the studied applications. 

\end{enumerate}



%These log processing tools are used to generate information for capacity planning of large-scale systems~\cite{hassan2008industrial,nagappan2009efficiently}, to monitor system health~\cite{bitincka2010optimizing} or to detect abnormal system behavior~\cite{JiangICSM2008}. These tools rely heavily on the log messages themselves and require continuous maintenance when the format or content of logs are changed.

% and use the data to answer the following research questions.

%\textbf{RQ1:} \textbf{How much do logs change over time and why do the changes occur?}
%
%Based on our quantitative analysis of the studied systems we identify three categories of change frequency in logs. If a log is changed more than four times we categorize it as \textsl{`Frequently Changed'}, if it has one to three changes, it is categorized as \textsl{`Changed'} and if there are no changes made we categorize it as \textsl{`Never Changed'}. We find that in our studied systems, 20-80\% of the logs are changed at least once throughout their lifespan.


%\textbf{RQ2:} \textbf{Can metrics from code, log and developer dimension help in explaining the stability of logs?}

%We collect the product and change metrics from three dimensions namely code, log and developer information. Our \textsl{random forest} achieves an accuracy of 89\%-91\% and recall of 71\%-91\%, when predicting which logs have higher likelihood of getting changed. We also identify significant metrics from each of the three dimensions, that affect the stability of logs. We find  developer experience, source lines of code, file ownership, log density in the file are strong predictors in classifying if a log will change in the future. 
 
 
% Our results show that product and process metrics obtained from code, log and developer information can help in identifying unstable logs in our studied systems. This can help in reducing the effort needed in the maintenance of log processing applications, as system maintainers can flag the logs that have the potential of being changed in subsequent releases and track them. 
 
The rest of this paper is organized as follows. Section~\ref{Methodology} presents the methodology for gathering and extracting data for our study. Section~\ref{analysis} presents the preliminary analysis to motivate our study. Section~\ref{prediction} describes the random forest classifier and the analysis results. Section~\ref{related} describes the prior research that is related to our work. Section~\ref{threats} discusses the threats to validity. Finally, Section~\ref{conc} concludes the paper.
 
 
% However, as these tools are not scalable for all companies and systems, companies prefer in house development or customization of these tools for their specific purposes. 