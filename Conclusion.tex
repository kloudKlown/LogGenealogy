Logs are snippets of code, added by developers to record valuable information. The recorded information is used by a plethora of log processing tools to assist in software testing, monitoring performance and system state comprehension. These log processing tools are completely dependent on the logs and hence are affected when logs are changed.

 In this paper we study the stability of logs using a random forest classifier. The classifier is used to predict which logs are more likely to change in the future using context and log data.  The highlights of our study are:

\begin{itemize}
	\item We find that 35\%-50\% of logs are changed at-least once.
	\item Our random forest classifier for predicting whether a log will change achieves a precision of 89\%-91\% and recall of 71\%-83\%. 
	\item We find that log density, SLOC, developer experience, file ownership are important predictors of log stability in the studied applications.  	
%	\item We find that log density has negative correlation in all projects which suggests that when source code is well logged i.e., more logs per lines of code, the logs convey the needed information and are more stable. 
	
%	We find a negative correlation between developer experience and log changes from the developer dimension. We find that the number of comments in source code, also has negative correlation towards log changes. 
\end{itemize}

%Our findings highlight that we can predict which logs have a higher likelihood of getting changed when they are introduced. This information can be used by system administrators and practitioners, to identify logs which have a higher chance of affecting the log processing tools and prevent failure of these tools.  



